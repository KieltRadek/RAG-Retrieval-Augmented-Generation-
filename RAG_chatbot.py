# -*- coding: utf-8 -*-
"""03_RAG_Bielik-11B-v2.6-Instruct-bnb-4bit

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Hc922B6KJxljzAYKEFxIG5OH_hp-P5vI
"""

#https://huggingface.co/speakleash/Bielik-11B-v2.6-Instruct
# ===============================
# 1. Instalacje
# ===============================
# !pip install -U bitsandbytes sentence-transformers faiss-cpu transformers accelerate tf-keras sentencepiece
# ===============================
# 2. Importy
# ===============================
import torch
import numpy as np
import faiss
import re
from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    pipeline,
    BitsAndBytesConfig
)
from sentence_transformers import SentenceTransformer

# ===============================
# 3. Model językowy – BIELIK -----STAREEEEE
# ===============================
"""model_name = "speakleash/Bielik-11B-v2.6-Instruct-bnb-4bit"
tokenizer = AutoTokenizer.from_pretrained(model_name)
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_compute_dtype=torch.float16,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4"
)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    quantization_config=bnb_config,
    device_map="cpu"
)
generator = pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer
)"""
# ===============================
# 3. Model językowy – Qwen 2.5B 1.5B-Instruct 
# ===============================

model_name = "Qwen/Qwen2.5-1.5B-Instruct"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    device_map="auto",
    torch_dtype="auto"
)

generator = pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer
)
# ===============================
# 4. Dokument źródłowy (Procedura kalibracji systemu wizyjnego kamera-robot)
# ===============================
document = """
Procedura kalibracji systemu wizyjnego kamera-robot jest dokumentem obowiązującym dla operatorów komórek zrobotyzowanych. Kalibracja ma na celu ustalenie precyzyjnej transformacji geometrycznej pomiędzy układem współrzędnych kamery, robota, narzędzia i stołu. Procedurę może wykonywać wyłącznie operator posiadający certyfikat Vision System Level 2. Przed rozpoczęciem upewnij się, że robot jest w trybie T1 (Manual Reduced Speed), a strefa robocza jest odgrodzona. Do kalibracji wymagany jest precyzyjny wzorzec kalibracyjny (szachownica) o znanej dokładności geometrycznej. Oświetlenie stacji musi być włączone i ustabilizowane przez min. 10 minut. Pierwszym etapem jest kalibracja parametrów wewnętrznych kamery (Camera Intrinsics). Należy zamontować wzorzec szachownicy na sztywnej płycie na stole roboczym. Wykonaj serię 15 ujęć wzorca poruszając nim w polu widzenia kamery. Uruchom algorytm kalibracji wewnętrznej w oprogramowaniu wizyjnym. Algorytm obliczy dystorsję obiektywu (k1, k2, p1, p2) oraz parametry macierzy kamery (fx, fy, cx, cy). Błąd reprojekcji RMS musi być mniejszy niż 0.3 piksela dla zaakceptowania kalibracji. Drugim etapem jest kalibracja punktu centralnego narzędzia (Tool Center Point - TCP). Zainstaluj narzędzie kalibracyjne (punktownik) w miejsce chwytaka. Uruchom procedurę 4-point TCP calibration w teach pendantzie robota. Podejdź punktownikiem do wybranego, stałego punktu odniesienia z czterech różnych orientacji końcówki robota. Zatwierdź punkty aby kontroler obliczył dokładną pozycję TCP. Zweryfikuj TCP poprzez podjechanie do tego samego punktu z innych orientacji; dopuszczalne odchylenie to mniej niż 0.05 mm. Trzecim etapem jest kalibracja relacji kamera-robot (Hand-Eye Calibration) dla kamery stacjonarnej. Ustaw wzorzec kalibracyjny w polu widzenia kamery i zapamiętaj jego pozycję w układzie kamery. Zamocuj na robocie precyzyjny wskaźnik (igłę) o znanym TCP. Doprowadź wskaźnik robota do fizycznego środka przynajmniej 3 różnych punktów na wzorcu. Zapisz za każdym razem pozycję robota oraz pozycję punktu w układzie kamery. Wprowadź pary punktów do dedykowanego narzędzia kalibracyjnego. Uruchom algorytm Point-Based Calibration (np. wykorzystujący SVD) aby obliczyć transformację T_R_C. Błąd średniokwadratowy (RMSE) tej transformacji musi być mniejszy niż 0.15 mm. Ostatnim etapem jest walidacja i dokumentacja. Przetestuj kalibrację na 5 losowo ułożonych obiektach testowych. Zmierz offset między pożądaną a osiągniętą pozycją chwytaka; średni błąd nie może przekroczyć 0.2 mm. Przygotuj raport kalibracyjny zawierający wszystkie parametry, wykresy błędów i wynik testu. Zapisz parametry w nieulotnej pamięci robota (SRAM) oraz w systemie nadrzędnym (MES). W przypadku dużego błędu w Fazie 3 sprawdź poprawność kalibracji TCP i luz mechaniczny chwytaka. W przypadku niespójnych wyników wizyjnych dostrój częstotliwość lamp stroboskopowych. Procedurę kalibracji należy powtarzać co 6 miesięcy lub po każdym uderzeniu/transporcie systemu. Odpowiedzialnym za nadzór nad procedurą jest Kierownik Utrzymania Ruchu Automatyki. Kontakt: Jan Kowalski jan.kowalski@firma.pl. Odpowiedzialnym za szkolenia i certyfikację operatorów jest Główny Inżynier Wizji. Kontakt: Anna Nowak anna.nowak@firma.pl.
"""
# ===============================
# 5. Chunking – dzielimy na zdania
def chunk_text(text):
    sentences = re.split(r"(?<=[.!?])\s+", text.strip())
    chunks = [s.strip() for s in sentences if s.strip()]
    return chunks

chunks = chunk_text(document)
# ===============================
# 6. Embeddingi (polski + multi)
# ===============================
embedder = SentenceTransformer("intfloat/multilingual-e5-base")

chunk_embeddings = embedder.encode(
    chunks,
    normalize_embeddings=True
)

dim = chunk_embeddings.shape[1]
index = faiss.IndexFlatIP(dim)
index.add(np.array(chunk_embeddings))
# ===============================
# 7. Retrieval
# ===============================
def retrieve_context(query, k=3):
    q_emb = embedder.encode([query], normalize_embeddings=True)
    scores, indices = index.search(np.array(q_emb), min(k, len(chunks)))
    top_chunks = []
    seen = set()
    for idx in indices[0]:
        chunk = chunks[idx]
        if chunk in seen:
            continue
        seen.add(chunk)
        top_chunks.append(chunk)
    max_score = float(scores[0][0]) if scores.size > 0 else 0.0
    return "\n\n".join(top_chunks), max_score

# ===============================
# 7b. Auto-detekcja stylu
# ===============================
def detect_style_automatically(question, context):
    """
    Automatycznie wybiera styl na podstawie:
    - Czy pytanie dotyczy dokumentu (podobieństwo embedingów)
    - Liczba słów w pytaniu
    - Zawartość pytania (znaki zapytania, wykrzykniki itp.)
    """
    # Embed pytania i kontekstu
    q_emb = embedder.encode([question], normalize_embeddings=True)
    c_emb = embedder.encode([context], normalize_embeddings=True)
    
    # Oblicz podobieństwo (score między 0 a 1)
    similarity = np.dot(q_emb[0], c_emb[0])
    
    # Analiza tekstu
    question_lower = question.lower()
    is_off_topic = similarity < 0.3  # Niska podobieństwo = pytanie spoza dokumentu
    is_technical = any(word in question_lower for word in 
                       ["jak", "jaki", "który", "gdzie", "ile", "kiedy", "procedure", "etap"])
    has_exclamation = "!" in question
    
    # Logika wyboru stylu
    if is_off_topic:
        # Pytanie spoza dokumentu - losuj między funny i strict
        return np.random.choice(["funny", "strict"], p=[0.6, 0.4])
    elif has_exclamation:
        # Pytanie z emocją - odpowiedz żartobliwie
        return "funny"
    elif is_technical:
        # Pytanie techniczne - odpowiedz profesjonalnie (casual)
        return "casual"
    else:
        # Domyślnie profesjonalnie
        return "strict"
    
# ===============================
# 8. Funkcja ask_bot
# ===============================
def ask_bot(question, style="auto"):
    """
    style: "auto" (automatycznie), "strict" (odmawia), "funny" (żartobliwie), 
           "vulgar" (wulgarnie), "casual" (zwyczajnie)
    """
    # pobierz kontekst z FAISS
    context, max_score = retrieve_context(question)

    # twarda odmowa, gdy brak kontekstu lub niski score
    MIN_SIMILARITY = 0.35
    if (not context.strip()) or max_score < MIN_SIMILARITY:
        print("-" * 80)
        print("PYTANIE:")
        print(question)
        print("-" * 40)
        print("KONTEKST:")
        print("Brak wystarczającego dopasowania do dokumentu (score < {:.2f}).".format(MIN_SIMILARITY))
        print("-" * 40)
        print("ODPOWIEDŹ (strict):")
        print("Nie znalazłem odpowiedzi w dokumencie.")
        print("-" * 80)
        return "Nie znalazłem odpowiedzi w dokumencie."

    # Automatycznie wybierz styl jeśli style="auto"
    if style == "auto":
        style = detect_style_automatically(question, context)

    # print pytania
    print("-" * 80)
    print("PYTANIE:")
    print(question)
    print("-" * 40)

    # print kontekstu
    print("KONTEKST:")
    if context.strip():
        print(context)
    else:
        print("Brak pasujących fragmentów.")
    print("-" * 40)

    # Wybór promptu na podstawie stylu
    if style == "strict":
        prompt = f"""Jesteś ścisłym asystentem opartym WYŁĄCZNIE na dokumencie źródłowym.
OBOWIĄZKOWE REGUŁY:
1. Odpowiadaj TYLKO na pytania dotyczące procedury kalibracji
2. Jeśli pytanie nie dotyczy dokumentu, ODMÓW odpowiedzi
3. Odpowiedź musi być krótka (max 2 zdania)

KONTEKST:
{context}

PYTANIE: {question}

ODPOWIEDŹ:"""

    elif style == "funny":
        prompt = f"""Jesteś asystentem z poczuciem humoru, opartym na dokumencie o kalibracji.
REGUŁY:
1. Jeśli pytanie dotyczy dokumentu, odpowiedz profesjonalnie i krótko
2. Jeśli pytanie NIE dotyczy dokumentu, odpowiedz śmiesznym żartem
3. Format: 1-2 zdania

KONTEKST:
{context}

PYTANIE: {question}

ODPOWIEDŹ:"""

    elif style == "vulgar":
        prompt = f"""Jesteś zdenerwowanym, wulgarnym mechanikiem który nienawidzi głupich pytań.
REGUŁY:
1. Jeśli pytanie dotyczy dokumentu, odpowiedz KRÓTKO ale z przekleństwami
2. Jeśli pytanie NIE dotyczy dokumentu, wyraź swoją frustrację wulgarnie
3. Używaj wulgaryzmów typu: kurwa, cholera, pierdolić, zajebiste, gówno itp.
4. Format: 1-2 zdania z przekleństwami

KONTEKST:
{context}

PYTANIE: {question}

ODPOWIEDŹ (wulgarnie):"""

    elif style == "casual":
        prompt = f"""Jesteś przyjaźnie nastawionym asystentem opartym na dokumencie.
REGUŁY:
1. Odpowiadaj naturalnie i konwersacyjnie (jak do kolegi)
2. Jeśli pytanie dotyczy dokumentu, wyjaśnij to w prosty sposób
3. Jeśli nie wiesz, powiedz: "Hej, tego nie mam w dokumentach!"

KONTEKST:
{context}

PYTANIE: {question}

ODPOWIEDŹ:"""

    else:
        prompt = f"""Jesteś asystentem opartym wyłącznie na dokumencie źródłowym.
Odpowiadaj KRÓTKO i PRECYZYJNIE na podstawie podanego kontekstu.
Jeśli pytanie nie dotyczy dokumentu, odpowiedz: "Nie znalazłem odpowiedzi w dokumencie."

KONTEKST:
{context}

PYTANIE: {question}

ODPOWIEDŹ:"""

    # generowanie odpowiedzi
    output = generator(
        prompt,
        max_new_tokens=240,
        temperature=0.01 if style == "strict" else 0.3 if style in ["funny", "vulgar"] else 0.15,
        do_sample=True,
        return_full_text=False
    )[0]["generated_text"]

    raw = output.strip().split("\n")[0].strip()
    if not raw:
        raw = "Nie otrzymałem odpowiedzi od modelu."
    answer = raw

    # print odpowiedzi
    print(f"ODPOWIEDŹ ({style}):")
    print(answer)
    print("-" * 80)

    return


# ===============================
# 9. Testy
# ===============================
# Podstawowe pytania o procedurę
#ask_bot("Ile etapów ma procedura kalibracji?")
#ask_bot("Co to jest TCP?")
ask_bot("Kto może wykonywać procedurę kalibracji?", style="vulgar")

# Pytania o szczegóły techniczne
ask_bot("Jaki jest maksymalny błąd reprojekcji RMS?")
ask_bot("Ile ujęć wzorca należy wykonać dla kamery?")
ask_bot("Jakie jest dopuszczalne odchylenie TCP?")
ask_bot("Co to jest Hand-Eye Calibration?")

# Pytania o procedury
ask_bot("Jak często należy powtarzać kalibrację?")
ask_bot("W jakim trybie powinien być robot przed rozpoczęciem?")
ask_bot("Gdzie zapisać parametry kalibracji?")
ask_bot("Co zrobić w przypadku dużego błędu w Fazie 3?")

# Pytania o osoby kontaktowe"""
ask_bot("Kto odpowiada za szkolenia operatorów?")
ask_bot("Jaki jest kontakt do Jana Kowalskiego?")
ask_bot("Kto jest Głównym Inżynierem Wizji?")

# Pytania o sprzęt i warunki
ask_bot("Jaki wzorzec jest potrzebny do kalibracji?")
ask_bot("Ile czasu musi być włączone oświetlenie przed kalibracją?")
ask_bot("Ile obiektów testowych należy użyć do walidacji?")

# Pytania ogólne (off-topic)
ask_bot("Ile wynosi prędkość światła?")
ask_bot("Kto jest prezydentem Polski?")
ask_bot("Jak ugotować jajko na twardo?")
ask_bot("Jaka jest stolica Francji?")

# Pytania o inne tematy techniczne
ask_bot("Jak zaprogramować w Pythonie?")
ask_bot("Co to jest blockchain?")
ask_bot("Jak działa silnik Diesla?")

# Pytania absurdalne
ask_bot("Czy roboty marzą o elektrycznych owcach?")
ask_bot("Dlaczego niebo jest niebieskie?")

# Częściowo związane
ask_bot("Co to jest kalibracja?")  # Ogólne, ale w dokumencie
ask_bot("Do czego służy robot?")  # Może być w kontekście
ask_bot("Co to jest kamera?")  # Wspomniane, ale nie wyjaśnione

# Pytania wymagające wnioskowania
ask_bot("Czy mogę sam rozkręcić robota?")  # Wymaga interpretacji
ask_bot("Czy każdy może użyć kamery?")  # Pośrednio w dokumencie