# ğŸ¤– RAG Chatbot - Retrieval-Augmented Generation

Inteligentny chatbot oparty na architekturze **RAG (Retrieval-Augmented Generation)** z automatycznÄ… detekcjÄ… stylu odpowiedzi. Projekt wykorzystuje modele jÄ™zykowe do generowania odpowiedzi na podstawie specjalistycznej dokumentacji technicznej.

## ğŸ“‹ Spis treÅ›ci

- [Opis projektu](#opis-projektu)
- [FunkcjonalnoÅ›ci](#funkcjonalnoÅ›ci)
- [Technologie](#technologie)
- [Instalacja](#instalacja)
- [UÅ¼ycie](#uÅ¼ycie)
- [Architektura](#architektura)
- [PrzykÅ‚ady](#przykÅ‚ady)
- [Dokumentacja badawcza](#dokumentacja-badawcza)

## ğŸ¯ Opis projektu

RAG Chatbot to inteligentny asystent zaprojektowany do odpowiadania na pytania dotyczÄ…ce **procedury kalibracji systemu wizyjnego kamera-robot**. System Å‚Ä…czy w sobie:

- **Retrieval** - wyszukiwanie semantyczne w bazie wiedzy (FAISS)
- **Generation** - generowanie odpowiedzi za pomocÄ… LLM (Qwen 2.5)
- **Auto-detection** - automatyczne dostosowanie stylu odpowiedzi

### GÅ‚Ã³wne zastosowanie
- Wsparcie operatorÃ³w komÃ³rek zrobotyzowanych
- Asystent do dokumentacji technicznej
- System Q&A dla procedur przemysÅ‚owych

## âš¡ FunkcjonalnoÅ›ci

### ğŸ¨ Style odpowiedzi (automatyczna detekcja)

- **Strict** - formalne, dokÅ‚adne odpowiedzi dla pytaÅ„ technicznych
- **Casual** - przyjazne, konwersacyjne wyjaÅ›nienia
- **Funny** - humorystyczne odpowiedzi dla pytaÅ„ poza tematem
- **Vulgar** - wulgarny styl (eksperymentalny)

### ğŸ›¡ï¸ Guardrails

- Automatyczna odmowa odpowiedzi dla pytaÅ„ spoza dokumentu
- PrÃ³g podobieÅ„stwa (MIN_SIMILARITY = 0.35)
- Deduplikacja powtarzajÄ…cych siÄ™ fragmentÃ³w kontekstu
- Walidacja jakoÅ›ci retrieval (max score tracking)

### ğŸ” Zaawansowany Retrieval

- Semantyczne wyszukiwanie z FAISS IndexFlatIP
- Embeddingi wielojÄ™zyczne (multilingual-e5-base)
- Chunking na poziomie zdaÅ„
- Top-k retrieval z deduplikacjÄ…

## ğŸ› ï¸ Technologie

| Komponent | Technologia |
|-----------|-------------|
| **Model LLM** | Qwen/Qwen2.5-1.5B-Instruct |
| **Embeddings** | intfloat/multilingual-e5-base |
| **Vector DB** | FAISS (IndexFlatIP) |
| **Framework** | Transformers, Sentence-Transformers |
| **Quantization** | BitsAndBytes (opcjonalnie) |

## ğŸ“¦ Instalacja

### Wymagania wstÄ™pne
- Python 3.8+
- pip / conda

### Kroki instalacji

```bash
# Klonowanie repozytorium
git clone https://github.com/KieltRadek/RAG-Retrieval-Augmented-Generation-.git
cd RAG-Retrieval-Augmented-Generation-

# Instalacja zaleÅ¼noÅ›ci
pip install -U bitsandbytes sentence-transformers faiss-cpu transformers accelerate tf-keras sentencepiece torch numpy
```

**Uwaga**: Na GPU z CUDA moÅ¼na uÅ¼yÄ‡ `faiss-gpu` dla lepszej wydajnoÅ›ci.

## ğŸš€ UÅ¼ycie

### Podstawowe uÅ¼ycie

```python
# Uruchomienie chatbota
python RAG_chatbot.py

# Zadawanie pytaÅ„
ask_bot("Ile etapÃ³w ma procedura kalibracji?")
ask_bot("Co to jest TCP?")
ask_bot("Kto moÅ¼e wykonywaÄ‡ procedurÄ™ kalibracji?")
```

### Parametry funkcji `ask_bot`

```python
ask_bot(question, style="auto")
```

**Parametry:**
- `question` (str): Pytanie do chatbota
- `style` (str): Styl odpowiedzi
  - `"auto"` - automatyczna detekcja (domyÅ›lnie)
  - `"strict"` - formalne odpowiedzi
  - `"casual"` - przyjazne wyjaÅ›nienia
  - `"funny"` - humorystyczne odpowiedzi
  - `"vulgar"` - wulgarny styl

### PrzykÅ‚ady pytaÅ„

#### âœ… Pytania ON-TOPIC (z dokumentu)
```python
ask_bot("Ile ujÄ™Ä‡ wzorca naleÅ¼y wykonaÄ‡ dla kamery?")
# â†’ "Zadanie polega na wykonaniu 15 ujÄ™Ä‡ wzorca..."

ask_bot("Kto odpowiada za szkolenia operatorÃ³w?")
# â†’ "GÅ‚Ã³wny InÅ¼ynier Wizji odpowiada za szkolenia operatorÃ³w."

ask_bot("Jaki jest maksymalny bÅ‚Ä…d reprojekcji RMS?")
# â†’ "BÅ‚Ä…d reprojekcji RMS musi byÄ‡ mniejszy niÅ¼ 0.3 piksela."
```

#### âŒ Pytania OFF-TOPIC (poza dokumentem)
```python
ask_bot("Ile wynosi prÄ™dkoÅ›Ä‡ Å›wiatÅ‚a?")
# â†’ "Hej, tego nie mam w dokumentach!"

ask_bot("Jak ugotowaÄ‡ jajko na twardo?")
# â†’ "Hej! Jako asystent nie jestem w stanie pomÃ³c..."
```

## ğŸ—ï¸ Architektura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Pytanie   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Embedding (E5-base)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FAISS Retrieval (k=3)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Score Validation       â”‚
â”‚  (threshold: 0.35)      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Style Auto-Detection   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Prompt Construction    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM Generation         â”‚
â”‚  (Qwen 2.5-1.5B)        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OdpowiedÅº  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### SzczegÃ³Å‚y komponentÃ³w

#### 1. **Chunking**
```python
def chunk_text(text):
    sentences = re.split(r"(?<=[.!?])\s+", text.strip())
    chunks = [s.strip() for s in sentences if s.strip()]
    return chunks
```
- Dzieli dokument na **pojedyncze zdania**
- Eliminuje puste fragmenty
- Zapobiega powtÃ³rzeniom w kontekÅ›cie

#### 2. **Retrieval**
```python
def retrieve_context(query, k=3):
    q_emb = embedder.encode([query], normalize_embeddings=True)
    scores, indices = index.search(np.array(q_emb), min(k, len(chunks)))
    # Deduplikacja + zwrÃ³cenie max_score
```
- FAISS IndexFlatIP (cosine similarity)
- Top-k retrieval (k=3)
- Zwraca kontekst + max similarity score

#### 3. **Auto-Detection**
```python
def detect_style_automatically(question, context):
    similarity = np.dot(q_emb[0], c_emb[0])
    
    if similarity < 0.3:  # OFF-TOPIC
        return np.random.choice(["funny", "strict"])
    elif has_exclamation:
        return "funny"
    elif is_technical:
        return "casual"
    else:
        return "strict"
```

#### 4. **Generation**
- Model: **Qwen/Qwen2.5-1.5B-Instruct**
- max_new_tokens: **240**
- Temperature:
  - Strict: **0.01** (deterministyczny)
  - Funny/Vulgar: **0.3** (kreatywny)
  - Casual: **0.15** (balansowany)

## ğŸ“Š PrzykÅ‚ady dziaÅ‚ania

### PrzykÅ‚ad 1: Pytanie techniczne
```
PYTANIE:
Co to jest TCP?

KONTEKST:
ZatwierdÅº punkty aby kontroler obliczyÅ‚ dokÅ‚adnÄ… pozycjÄ™ TCP.
Zamocuj na robocie precyzyjny wskaÅºnik (igÅ‚Ä™) o znanym TCP.

ODPOWIEDÅ¹ (strict):
TCP to pole w ukÅ‚adzie, ktÃ³re okreÅ›la poÅ‚oÅ¼enie roboty w przestrzeni.
```

### PrzykÅ‚ad 2: Pytanie off-topic
```
PYTANIE:
Ile wynosi prÄ™dkoÅ›Ä‡ Å›wiatÅ‚a?

KONTEKST:
[Brak wystarczajÄ…cego dopasowania]

ODPOWIEDÅ¹ (strict):
Nie znalazÅ‚em odpowiedzi w dokumencie.
```

### PrzykÅ‚ad 3: Pytanie o szczegÃ³Å‚y
```
PYTANIE:
Ile ujÄ™Ä‡ wzorca naleÅ¼y wykonaÄ‡ dla kamery?

KONTEKST:
Wykonaj seriÄ™ 15 ujÄ™Ä‡ wzorca poruszajÄ…c nim w polu widzenia kamery.

ODPOWIEDÅ¹ (casual):
Zadanie polega na wykonaniu 15 ujÄ™Ä‡ wzorca. KaÅ¼dy z nich powinien byÄ‡
wykonany w rÃ³Å¼nych kÄ…tach widzenia kamery.
```

## ğŸ“ Dokumentacja badawcza

Projekt zawiera szczegÃ³Å‚owÄ… notatkÄ™ badawczÄ… (`notatka_badawcza.txt`) opisujÄ…cÄ…:

- **Wykonane modyfikacje** - migracja z Bielik 11B na Qwen 2.5
- **Metody testowania** - pytania on-topic, off-topic, absurdalne
- **Fragmenty dialogÃ³w** - rzeczywiste odpowiedzi systemu
- **Obserwowane rÃ³Å¼nice** - wpÅ‚yw zmian na jakoÅ›Ä‡ odpowiedzi
- **Rekomendacje** - optymalizacja dla CPU/GPU
- **Pytania kontrolne** - przygotowanie do obrony projektu

## ğŸ” Pytania kontrolne (FAQ)

<details>
<summary><b>Jaki model LLM zostaÅ‚ uÅ¼yty i dlaczego?</b></summary>

**Qwen/Qwen2.5-1.5B-Instruct** - maÅ‚y model (1.5B parametrÃ³w), dziaÅ‚ajÄ…cy efektywnie na CPU/GPU z niskimi wymaganiami, zapewniajÄ…cy sensowne odpowiedzi instruktaÅ¼owe.
</details>

<details>
<summary><b>Czym jest architektura RAG?</b></summary>

**Retrieval-Augmented Generation** - najpierw wyszukiwanie fragmentÃ³w (embedding + FAISS), potem generacja z uÅ¼yciem tych fragmentÃ³w jako kontekstu, co ogranicza halucynacje.
</details>

<details>
<summary><b>Jak dziaÅ‚a funkcja retrieve_context?</b></summary>

Embedduje pytanie, szuka w FAISS IndexFlatIP top-k (min(k, liczba chunkÃ³w)), zwraca unikalne zdania. Parametr **k** okreÅ›la liczbÄ™ fragmentÃ³w, **score** mierzy podobieÅ„stwo (0-1).
</details>

<details>
<summary><b>Jakie sÄ… ograniczenia obecnego podejÅ›cia?</b></summary>

- Model moÅ¼e halucynowaÄ‡ przy sÅ‚abym kontekÅ›cie
- Wysokie MIN_SIMILARITY (0.35) daje wiÄ™cej odmÃ³w
- Brak jeszcze testÃ³w jednostkowych
- CPU: wolniejsza generacja przy duÅ¼ych pakietach testowych
</details>

## ğŸ“ Rekomendacje

### Dla uÅ¼ytkownikÃ³w CPU:
- Uruchamiaj pojedyncze pytania
- Zakomentuj pakiet testowy na koÅ„cu `RAG_chatbot.py`
- RozwaÅ¼ model o mniejszej liczbie parametrÃ³w

### Dla uÅ¼ytkownikÃ³w GPU:
- MoÅ¼na zwiÄ™kszyÄ‡ `k` w retrieval (np. k=5)
- UÅ¼yÄ‡ `faiss-gpu` zamiast `faiss-cpu`
- RozwaÅ¼yÄ‡ wiÄ™kszy model (np. Qwen 7B)

### Parametry do tuningu:
- `k=3` w `retrieve_context`
- `MIN_SIMILARITY=0.35` w `ask_bot`
- `max_new_tokens=240`
- `temperature` per styl (strict: 0.01, casual: 0.15, funny: 0.3)

## ğŸ“„ Licencja

Projekt stworzony w celach edukacyjnych/badawczych.

## ğŸ‘¤ Autor

**Radek Kielt** - [KieltRadek](https://github.com/KieltRadek)

## ğŸ™ PodziÄ™kowania

- [SpeakLeash](https://huggingface.co/speakleash) - polski model Bielik
- [Qwen Team](https://huggingface.co/Qwen) - model Qwen 2.5
- [FAISS](https://github.com/facebookresearch/faiss) - efektywne wyszukiwanie wektorowe
- [Hugging Face](https://huggingface.co/) - infrastruktura ML

---

â­ **JeÅ›li projekt Ci siÄ™ podoba, zostaw gwiazdkÄ™!** â­